{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "202bc228-22a4-4de1-81b2-12813958dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3221a48-ead2-4805-953d-323d47ce7659",
   "metadata": {},
   "source": [
    "# Tokenization using spacy.blank(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "07c285e2-767e-4869-a819-b90dbb8163d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr.\n",
      "Dtrange\n",
      "loves\n",
      "pav\n",
      "bhaji\n",
      "of\n",
      "mumbai\n",
      "as\n",
      "it\n",
      "coasts\n",
      "only\n",
      "2\n",
      "$\n",
      "per\n",
      "plate\n",
      ".\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "doc = nlp(\"Dr. Dtrange loves pav bhaji of mumbai as it coasts only 2$ per plate.\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62db5bd2-b462-45ae-9cdc-2dad2d8874ee",
   "metadata": {},
   "source": [
    "# Span Object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "44b2c724-6ce8-4c9c-b59a-047a65911983",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Dtrange loves pav bhaji\n",
      "<class 'spacy.tokens.span.Span'>\n"
     ]
    }
   ],
   "source": [
    "span = doc[0:5]\n",
    "print(span)\n",
    "print(type(span))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4ee236d-4afd-4152-a9d0-ed0cc60b85b7",
   "metadata": {},
   "source": [
    "# Using index and attributes  to grab tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "c07d7013-485b-4b21-bdc5-6e98733946a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"Tony gave two $ to Peter.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c02ee410-2fca-48a1-b70f-e1ced701eff2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony\n",
      "<class 'spacy.tokens.token.Token'>\n",
      "False\n",
      "['_', '__bytes__', '__class__', '__delattr__', '__dir__', '__doc__', '__eq__', '__format__', '__ge__', '__getattribute__', '__gt__', '__hash__', '__init__', '__init_subclass__', '__le__', '__len__', '__lt__', '__ne__', '__new__', '__pyx_vtable__', '__reduce__', '__reduce_ex__', '__repr__', '__setattr__', '__sizeof__', '__str__', '__subclasshook__', '__unicode__', 'ancestors', 'check_flag', 'children', 'cluster', 'conjuncts', 'dep', 'dep_', 'doc', 'ent_id', 'ent_id_', 'ent_iob', 'ent_iob_', 'ent_kb_id', 'ent_kb_id_', 'ent_type', 'ent_type_', 'get_extension', 'has_dep', 'has_extension', 'has_head', 'has_morph', 'has_vector', 'head', 'i', 'idx', 'iob_strings', 'is_alpha', 'is_ancestor', 'is_ascii', 'is_bracket', 'is_currency', 'is_digit', 'is_left_punct', 'is_lower', 'is_oov', 'is_punct', 'is_quote', 'is_right_punct', 'is_sent_end', 'is_sent_start', 'is_space', 'is_stop', 'is_title', 'is_upper', 'lang', 'lang_', 'left_edge', 'lefts', 'lemma', 'lemma_', 'lex', 'lex_id', 'like_email', 'like_num', 'like_url', 'lower', 'lower_', 'morph', 'n_lefts', 'n_rights', 'nbor', 'norm', 'norm_', 'orth', 'orth_', 'pos', 'pos_', 'prefix', 'prefix_', 'prob', 'rank', 'remove_extension', 'right_edge', 'rights', 'sent', 'sent_start', 'sentiment', 'set_extension', 'set_morph', 'shape', 'shape_', 'similarity', 'subtree', 'suffix', 'suffix_', 'tag', 'tag_', 'tensor', 'text', 'text_with_ws', 'vector', 'vector_norm', 'vocab', 'whitespace_']\n"
     ]
    }
   ],
   "source": [
    "token0 = doc[0]\n",
    "print(token0)\n",
    "print(type(token0))\n",
    "print(token0.like_num)\n",
    "print(dir(token0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8dd0e902-adc5-4262-b980-a01939e4fcb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "two\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "token2 = doc[2]\n",
    "print(token2.text)\n",
    "print(token2.like_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "35e24df6-c661-46af-bde4-8ee818ffd230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "$\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "token3 = doc[3]\n",
    "print(token3)\n",
    "print(token3.is_currency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "2f2c069b-6a52-465d-b006-4bb0463c92bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tony ==> index:  0 is_alpha:  True is_punch:  False like_num:  False is_currency:  False\n",
      "gave ==> index:  1 is_alpha:  True is_punch:  False like_num:  False is_currency:  False\n",
      "two ==> index:  2 is_alpha:  True is_punch:  False like_num:  True is_currency:  False\n",
      "$ ==> index:  3 is_alpha:  False is_punch:  False like_num:  False is_currency:  True\n",
      "to ==> index:  4 is_alpha:  True is_punch:  False like_num:  False is_currency:  False\n",
      "Peter ==> index:  5 is_alpha:  True is_punch:  False like_num:  False is_currency:  False\n",
      ". ==> index:  6 is_alpha:  False is_punch:  True like_num:  False is_currency:  False\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, \"==>\", \"index: \", token.i,\n",
    "          \"is_alpha: \", token.is_alpha,\n",
    "          \"is_punch: \", token.is_punct,\n",
    "          \"like_num: \", token.like_num,\n",
    "          \"is_currency: \", token.is_currency,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba435309-e3d1-4645-bd94-94f70ea03e6f",
   "metadata": {},
   "source": [
    "# Collecting email ids of students from student informations sheet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "1cd080ec-0ad2-476f-ad42-e3eb6b89f50b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Dayton high school, 8th grade students information\\n',\n",
       " '===================================================\\n',\n",
       " '\\n',\n",
       " 'Name\\tbirthday\\temail\\n',\n",
       " '-----\\t--------\\t-----\\n',\n",
       " 'Virat\\t5 June, 1882\\tvirat@kohli.com\\n',\n",
       " 'Maria\\t12 April, 2001\\tmaria@sharapova.com\\n',\n",
       " 'Serena\\t24 June, 1998\\tserena@williams.com\\n',\n",
       " 'Joe\\t1 May, 1997\\tjoe@root.com']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open(\"students.txt\") as f:\n",
    "    text = f.readlines()\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3d0353bd-6713-4066-bd9f-a55e55e314ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Dayton high school, 8th grade students information\\n ===================================================\\n \\n Name\\tbirthday\\temail\\n -----\\t--------\\t-----\\n Virat\\t5 June, 1882\\tvirat@kohli.com\\n Maria\\t12 April, 2001\\tmaria@sharapova.com\\n Serena\\t24 June, 1998\\tserena@williams.com\\n Joe\\t1 May, 1997\\tjoe@root.com'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = ' '.join(text)\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "01f9686a-b928-487e-8c5c-e659ad1a411d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['virat@kohli.com',\n",
       " 'maria@sharapova.com',\n",
       " 'serena@williams.com',\n",
       " 'joe@root.com']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "emails = []\n",
    "for token in doc:\n",
    "    if token.like_email:\n",
    "        emails.append(token.text)\n",
    "emails"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61a2d658-da0b-4d53-a80b-866fd8dffc62",
   "metadata": {},
   "source": [
    "# Support in other Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "63a0806a-c465-43d2-84b3-e256972e2d27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "আমি False False\n",
      "তাকে False False\n",
      "২ False True\n",
      "হাজার False False\n",
      "৳ True False\n",
      "দিয়েছিলাম False False\n",
      ", False False\n",
      "সে False False\n",
      "তা False False\n",
      "ফেরত False False\n",
      "দেয়নি False False\n",
      "। False False\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.blank(\"bn\")\n",
    "\n",
    "doc = nlp(\"আমি তাকে ২ হাজার ৳ দিয়েছিলাম, সে তা ফেরত দেয়নি।\")\n",
    "\n",
    "for token in doc:\n",
    "    print(token, token.is_currency, token.like_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "20848e81-dfdd-47f5-99cf-c9318e0e54f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gimme', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp = spacy.blank(\"en\")\n",
    "\n",
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "token = [token.text for token in doc]\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c882ea1b-22f8-4b55-9694-c05b2a2dedcf",
   "metadata": {},
   "source": [
    "# Customize Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b40909c5-067e-4b1d-8fda-395a2f51baae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['gim', 'me', 'double', 'cheese', 'extra', 'large', 'healthy', 'pizza']"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from spacy.symbols import ORTH\n",
    "\n",
    "nlp.tokenizer.add_special_case(\"gimme\", [\n",
    "    {ORTH: \"gim\"},\n",
    "    {ORTH: \"me\"}\n",
    "])\n",
    "\n",
    "doc = nlp(\"gimme double cheese extra large healthy pizza\")\n",
    "token = [token.text for token in doc]\n",
    "token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b951cef2-8a87-452e-9d9b-9fa6c4ac42ae",
   "metadata": {},
   "source": [
    "# Sentence Tokenization or Segmentation adding pipe 'sentencizer' manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6bb116fa-735e-4ec9-8731-bf03b03c3f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.pipeline.sentencizer.Sentencizer at 0x24c58bc84c0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe('sentencizer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e125c422-1676-48c8-acee-542c552b2efb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sentencizer']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.pipe_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dad03c51-a2f6-47fa-a888-ac2956dd4b49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dr. Strange loves fuchka in Dhaka.\n",
      "Hulk loves puri in Sylhet\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Dr. Strange loves fuchka in Dhaka. Hulk loves puri in Sylhet\")\n",
    "\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c98604-83b4-484b-ae48-526731747ec0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
